{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ram/miniforge3/envs/sitewiz/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Weights & Biases user: sitewiz-ram.\n",
      "View Weave data at https://wandb.ai/sitewiz/Agents/weave\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<weave.trace.weave_client.WeaveClient at 0x12a1eb500>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weave\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "project = os.getenv('WANDB_PROJECT')\n",
    "weave.init(project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{} (43% o) : {}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['hello', 'world']\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{hi}\".format(hi=[\"hello\", \"world\"])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-west-2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "table_name =os.environ.get('AWS_REIIGION') or 'us-west-2'\n",
    "table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID: PVT_kwDOCOLC8s4AyzdZ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "def get_project_id(org_name, project_number, project_name):\n",
    "    # Get token from environment variable\n",
    "    token = os.getenv('GITHUB_TOKEN')\n",
    "    if not token:\n",
    "        raise ValueError(\"GITHUB_TOKEN environment variable is not set\")\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "        \"Accept\": \"application/vnd.github.v3+json\"\n",
    "    }\n",
    "    \n",
    "    # GraphQL query to get project ID\n",
    "    query = \"\"\"\n",
    "    query($org: String!, $number: Int!) {\n",
    "        organization(login: $org) {\n",
    "            projectV2(number: $number) {\n",
    "                id\n",
    "                title\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    variables = {\n",
    "        \"org\": org_name,\n",
    "        \"number\": project_number\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"query\": query,\n",
    "        \"variables\": variables\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.github.com/graphql\",\n",
    "            json=data,\n",
    "            headers=headers\n",
    "        )\n",
    "        response.raise_for_status()  # Raise exception for bad status codes\n",
    "        \n",
    "        result = response.json()\n",
    "        \n",
    "        # Check for errors in the GraphQL response\n",
    "        if 'errors' in result:\n",
    "            raise Exception(f\"GraphQL Error: {result['errors']}\")\n",
    "        \n",
    "        # Verify the project name matches and return the ID\n",
    "        project_data = result.get('data', {}).get('organization', {}).get('projectV2', {})\n",
    "        if project_data.get('title') == project_name:\n",
    "            return project_data.get('id')\n",
    "        raise ValueError(f\"Project with name '{project_name}' not found\")\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise Exception(f\"API request failed: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        project_id = get_project_id(\n",
    "            org_name=\"SitewizAI\",\n",
    "            project_number=21,\n",
    "            project_name=\"Evaluations\"\n",
    "        )\n",
    "        print(f\"Project ID: {project_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating index: An error occurred (ValidationException) when calling the UpdateTable operation: One or more parameter values were invalid: Neither ReadCapacityUnits nor WriteCapacityUnits can be specified for index: TimestampIndex when BillingMode is PAY_PER_REQUEST\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "def create_timestamp_index():\n",
    "    dynamodb = boto3.client('dynamodb')\n",
    "    table_name = 'EvaluationsTable'\n",
    "    \n",
    "    try:\n",
    "        response = dynamodb.update_table(\n",
    "            TableName=table_name,\n",
    "            AttributeDefinitions=[\n",
    "                {\n",
    "                    'AttributeName': 'type',\n",
    "                    'AttributeType': 'S'\n",
    "                },\n",
    "                {\n",
    "                    'AttributeName': 'timestamp',\n",
    "                    'AttributeType': 'N'\n",
    "                },\n",
    "            ],\n",
    "            GlobalSecondaryIndexUpdates=[\n",
    "                {\n",
    "                    'Create': {\n",
    "                        'IndexName': 'type-timestamp-index',\n",
    "                        'KeySchema': [\n",
    "                            {\n",
    "                                'AttributeName': 'type',\n",
    "                                'KeyType': 'HASH'\n",
    "                            },\n",
    "                            {\n",
    "                                'AttributeName': 'timestamp',\n",
    "                                'KeyType': 'RANGE'\n",
    "                            },\n",
    "                        ],\n",
    "                        'Projection': {\n",
    "                            'ProjectionType': 'ALL'\n",
    "                        },\n",
    "                        'ProvisionedThroughput': {\n",
    "                            'ReadCapacityUnits': 5,\n",
    "                            'WriteCapacityUnits': 5\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        print(\"Index creation initiated:\", response)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating index: {e}\")\n",
    "\n",
    "create_timestamp_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching prompts: An error occurred (ResourceNotFoundException) when calling the Scan operation: Requested resource not found\n",
      "All prompts added to PromptRefsTable successfully.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize DynamoDB resource\n",
    "dynamodb = boto3.resource('dynamodb')\n",
    "\n",
    "# Get the PromptsTable\n",
    "prompts_table = dynamodb.Table('PromptsTable')\n",
    "\n",
    "# Get the PromptRefsTable\n",
    "prompt_refs_table = dynamodb.Table('PromptRefsTable')\n",
    "\n",
    "def get_all_prompts():\n",
    "    \"\"\"Fetch all prompts from DynamoDB PromptsTable.\"\"\"\n",
    "    try:\n",
    "        response = prompts_table.scan()\n",
    "        prompts = response.get('Items', [])\n",
    "        return prompts\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching prompts: {e}\")\n",
    "        return []\n",
    "\n",
    "def add_prompts_to_refs_table(prompts):\n",
    "    \"\"\"Add all prompts to the PromptRefsTable.\"\"\"\n",
    "    try:\n",
    "        for prompt in prompts:\n",
    "            prompt_ref = {\n",
    "                'ref': prompt['ref'],\n",
    "                'version': prompt.get('version', 'N/A'),\n",
    "                'content': prompt['content']\n",
    "            }\n",
    "            prompt_refs_table.put_item(Item=prompt_ref)\n",
    "        print(\"All prompts added to PromptRefsTable successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding prompts to PromptRefsTable: {e}\")\n",
    "\n",
    "# Fetch all prompts\n",
    "prompts = get_all_prompts()\n",
    "\n",
    "# Add prompts to PromptRefsTable\n",
    "add_prompts_to_refs_table(prompts)\n",
    "\n",
    "# Display the prompts\n",
    "for prompt in prompts:\n",
    "    print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%hello\n"
     ]
    }
   ],
   "source": [
    "print(\"%hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['hello']\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{['hello']}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ram/miniforge3/envs/sitewiz/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Weights & Biases user: sitewiz-ram.\n",
      "View Weave data at https://wandb.ai/sitewiz/Agents/weave\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type WeaveObject is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Save to JSON file\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraces.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[0;32m---> 40\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraces\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_traces\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m traces to traces.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/sitewiz/lib/python3.12/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/sitewiz/lib/python3.12/json/encoder.py:430\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m _floatstr(o)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 430\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n",
      "File \u001b[0;32m~/miniforge3/envs/sitewiz/lib/python3.12/json/encoder.py:326\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 326\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/sitewiz/lib/python3.12/json/encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/sitewiz/lib/python3.12/json/encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/sitewiz/lib/python3.12/json/encoder.py:326\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 326\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/sitewiz/lib/python3.12/json/encoder.py:439\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    438\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[0;32m--> 439\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/sitewiz/lib/python3.12/json/encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type WeaveObject is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import weave\n",
    "\n",
    "# Initialize Weave client\n",
    "client = weave.init(\"Agents\")\n",
    "\n",
    "# Fetch evaluation traces\n",
    "calls = client.get_calls(\n",
    "    filter={\"op_names\": [\"weave:///sitewiz/Agents/op/Evaluation.predict_and_score:*\"]},\n",
    "    sort_by=[{\"field\": \"started_at\", \"direction\": \"desc\"}],\n",
    ")\n",
    "\n",
    "# Number of traces to extract\n",
    "num_traces = min(10, len(calls))  # Ensure we don't exceed available traces\n",
    "\n",
    "# Function to clean conversation data\n",
    "def filterConversation(conversation):\n",
    "    for message in conversation:\n",
    "        message.pop(\"models_usage\", None)\n",
    "        message.pop(\"_class_name\", None)\n",
    "        message.pop(\"_bases\", None)\n",
    "    return conversation\n",
    "\n",
    "# Extract input-output pairs\n",
    "traces = []\n",
    "for i in range(num_traces):\n",
    "    try:\n",
    "        call = calls[i]\n",
    "\n",
    "        trace = {\n",
    "            \"input\": call.inputs.get(\"example\", \"N/A\"),\n",
    "            \"output\": call.output.get(\"scores\", {}).get(\"score\", \"N/A\"),\n",
    "        }\n",
    "        traces.append(trace)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "# Save to JSON file\n",
    "with open(\"traces.json\", \"w\") as json_file:\n",
    "    json.dump(traces, json_file, indent=4)\n",
    "\n",
    "print(f\"Saved {num_traces} traces to traces.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "call = calls[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WeaveDict({'self': ObjectRef(entity='sitewiz', project='Agents', name='Evaluation', _digest='kvT3vbFYRA4jvIYf5nCrSZYYrPPBT74WYoPZe2WfM6w', _extra=()), 'model': OpRef(entity='sitewiz', project='Agents', name='analyze_problem', _digest='ixyV5UXE8SNNiOcXZF8LXGPbxoKf1bvYtiEN9QN2Y7k', _extra=()), 'example': ObjectRef(entity='sitewiz', project='Agents', name='Dataset', _digest='FC17lgH1yef1TYQjyPlImfpk9FmbPduDxjkd44qHsYc', _extra=('attr', 'rows', 'id', 'FuLYEuHBXbOz8tbw1QtHDpMBY2CMYob7ZPtxv4SSFUU'))})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weave\n",
    "client = weave.init(\"Agents\")\n",
    "calls = client.get_calls(\n",
    "    filter={\"op_names\": [\"weave:///sitewiz/Agents/op/Evaluation.predict_and_score:*\"]},\n",
    "    sort_by=[{\"field\":\"started_at\",\"direction\":\"desc\"}],\n",
    ")\n",
    "num_traces = 10\n",
    "for i in range(num_traces):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "call = calls[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "call.output['model_output']\n",
    "call.inputs['example']\n",
    "trace = {\n",
    "    'input': call.inputs['example'],\n",
    "    'output': call.output['scores']['score'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WeaveDict({'question': 'Find a unique insight relevant to the business by diving into the data and finding interesting and useful metrics, basing off of an existing OKR.', 'business_context': '\"1. What are your main business objectives for the next 1-6 months?\\n(Select all that apply):\"\\t\"\\n\\nIncrease conversions, Improve user engagement, Engagement priorities: video views, scroll depth, clicks, map module engagement: https://rednavel.link/Gn7X7PTL \\n\\n2. What Objective Key Results (OKRs) are most important to you?\\n(Select up to three):\"\\t\"\\n\\nDecrease bounce rate, Enhance click-through rates (CTR), Form fills is by far #1...but when you say \"CTR\" I want to clarity that is on-site and not via Ads or SEO. How many click a button / viewed a section with that button...we\\'ve setup our Measurement this way via \"element visibility\" rules through GTM on the site and just wanted to clarity CTR means something different to us vs most. Viewing service pages and scroll + time on page (those together) are key. \\n\\n3. What tone or feeling do you want your website to convey?\\n(Select all that apply):\"\\t\\n\\nTrustworthy, Modern and sleek, Friendly and accessible\\n\\n4. Are there specific pages, sections, or features of your site you would like us to focus on improving?\\t\\n\\nForm pages are key: https://redstagfulfillment.com/get-pricing/ https://redstagfulfillment.com/contact-us/ as are service pages: https://redstagfulfillment.com/order-fulfillment/ and the rest of where those are found. \\n\\nConversion priorities: form fills for both \"Let\\'s Talk\" and \"Get Pricing\" which is the end of the funnel for this site. \\n\\n\\n\\n1. Who are your top competitors, and what differentiates your business from theirs?\\t\"\\n\\nhttps://www.shipbob.com/ https://www.shipmonk.com/ https://www.efulfillmentservice.com/ https://www.shipfusion.com/ https://www.fulfillrite.com/\\n\\n2. Have you identified specific strengths or weaknesses in your competitors’ websites or strategies? If so, what are they? \\n(E.g., “Competitor X has excellent navigation, but their checkout flow is slow.”)\"\\t\"\\n\\n1. Competitive Positioning: Red Stag doesn\\'t seem to focus on competing primarily on price. As mentioned in one meeting, \"we don\\'t try to compete on price. Like we try to be competitive on price, but that\\'s not where we\\'re trying to win.\"  2. Unique Selling Points: Red Stag appears to differentiate itself in a few ways:    - Strategic Location: They have only two locations across the US, which is mentioned as a strategic choice for cheaper ground shipping prices.    - Fulfillment Services: They position themselves as \"#1 in ecommerce fulfillment services,\" though the specific reasons for this claim weren\\'t detailed in the transcripts I found.  3. Value Propositions: There were discussions about highlighting Red Stag\\'s unique value propositions, such as potentially saving customers money on shipping due to their strategic locations.  4. Sales Process: There was mention of Red Stag having an \"intense\" sales process, with a focus on determining whether they can save potential clients money on shipping within a 15-minute call.\\n\\n3. Are there any ongoing or upcoming marketing campaigns, industry trends, seasonal changes, or external factors we should consider when making recommendations? If so, what are they? \\n(This could include holiday promotions, seasonal discounts, product launches, economic shifts, or emerging technologies.)\"\\t\"\\n\\nThey are in the busy time of the year, as everyone is making sure they are fulfilling their 3PL needs from their holiday orders. \\n\\n4. Are there specific audiences critical to your business success? How are they defined?\\n(E.g., “Tech-savvy millennials,” “Value-driven shoppers.”)\"\\t\"\\n\\nEcommerce business owners. Operations managers. \\n\\n1. What kind of suggestions are you most interested in?\\n(Select all that apply):\"\\t\"\\n\\n\\nImproving navigation or site layout, Enhancing CTAs or user pathways, Optimizing underperforming pages or features, Personalizing user experiences (e.g., quizzes, recommendations), Increasing conversions or revenue.\\n\\n2. Are there any suggestions or changes you explicitly do NOT want to see?\\n(E.g., “No popups” or “Don’t remove this feature.”)\"\\t\"\\n\\nNone\\n\\n3. What constraints should we keep in mind when making recommendations?\\n(Monthly development budget, availability of development team, platform limitations, time constraints etc.):\"\\t\\n\\nNone that comet to mind, but there is a limit on development every month (generally 2-3 tests). \\n\\n4.  Which tools and platforms do you have access to for site optimization across your entire stack? Please list all to eliminate infeasible suggestions.\\n\\nGA4, Microsoft Clarity, Hotjar for survey responses, they use Hubspot as well but we only have access to that through BigQuery. GAds and GSC I have access to as well...they have a healthy GAds budget every month, so any recommendations there would be what I\\'m looking for as well as those landing pages are a larger focus. \\nThe domain is \\'https://redstagfulfillment.com/\\'Please analyze this data and provide insights about user behavior and potential improvements:\\nHere are the other OKRs stored, choose one as a base for the insight (use its okr_name when calling store_insight):\\n[{\"markdown\": \"# OKR Analysis\\\\n\\\\n## Name\\\\nEnhance CTA Element Visibility on Heatmaps## Description\\\\nObjective: Improve daily click interactions on CTA elements by utilizing \\'heatmaps\\' data, tracking click events for improved CTA visibility and grouping by session dates.## Last Updated\\\\n2025-02-16 01:49:30\\\\n\\\\n## Metrics\\\\n- Metric Name: cta_interactions\\\\n- Description: Daily count of CTA interaction events (clicks) derived from the \\'heatmaps\\' table. Events are joined with session_recordings to obtain the materialized date for grouping.\\\\n- Date Range: 2025-02-09 to 2025-02-15\\\\n- Values:\\\\n  - 2025-02-09: 207\\\\n  - 2025-02-10: 519\\\\n  - 2025-02-11: 305\\\\n  - 2025-02-12: 239\\\\n  - 2025-02-13: 12\\\\n  - 2025-02-14: 0\\\\n  - 2025-02-15: 144\\\\n\", \"name\": \"Enhance CTA Element Visibility on Heatmaps\", \"insight_count\": 1}, {\"markdown\": \"# OKR Analysis\\\\n\\\\n## Name\\\\nForm Fill and On-Site CTR Evaluation## Description\\\\nObjective: Monitor increases in form fill conversion rates driven by engagements on \\'Contact Us\\' and \\'Get Pricing\\' conversion points, and enhance on-site click-through rate (CTR) efficacy as measured across pivotal session records.## Last Updated\\\\n2025-02-16 02:40:28\\\\n\\\\n## Metrics\\\\n- Metric Name: form_fill_conversion\\\\n- Description: Daily form fill conversion rate calculated as form fill events from funnels (base_url \\'https://redstagfulfillment.com/contact-us\\' or \\'https://redstagfulfillment.com/get-pricing\\') divided by total sessions from sessions, grouped by date.\\\\n- Date Range: 2025-02-09 to 2025-02-15\\\\n- Values:\\\\n  - 2025-02-09: 0.009009009009009009\\\\n  - 2025-02-10: 0.024475524475524476\\\\n  - 2025-02-11: 0.003745318352059925\\\\n  - 2025-02-12: 0.0\\\\n  - 2025-02-13: 0.058823529411764705\\\\n  - 2025-02-14: 0.0\\\\n  - 2025-02-15: 0.07692307692307693\\\\n\", \"name\": \"Form Fill and On-Site CTR Evaluation\", \"insight_count\": 1}]\\nHere are the other insights stored, DO NOT REPEAT THEM. WE WANT UNIQUE INSIGHTS\\n[{\"markdown\": \"# Insight Analysis\\\\n\\\\n## Data Statement\\\\nAnalysis of the heatmap data shows that the current average CTA interactions per day is 176.29 while a 25% uplift increases the target to 220.36. The reach fraction is \\\\u224830.32%, indicating that nearly one-third of total sessions engage with the CTA. Notably, the CTA element on the order fulfillment page at url \\'https://redstagfulfillment.com/order-fulfillment\\' shows significantly lower engagement compared to our overall metrics, highlighting a potential design or placement flaw.\\\\n\\\\n## Problem Statement\\\\nThe CTA engagement is underperforming relative to the uplift target. With a current average of 176.29 interactions versus a goal of 220.36, and given that 208 unique sessions are recording CTA activity, there is a clear indication that the design or positioning of the CTA element on the order fulfillment page might be causing a tracking or engagement issue.\\\\n\\\\n## Business Objective\\\\nIncrease user engagement and conversion rates by optimizing the design and placement of key CTA elements, thereby raising the average CTA interactions and overall site performance.\\\\n\\\\n## Hypothesis\\\\nBy redesigning or repositioning the underperforming CTA element on the order fulfillment page, we expect to achieve the 25% uplift target \\\\u2013 increasing average interactions from 176.29 to 220.36 per day \\\\u2013 and enhance the reach fraction, ultimately improving user engagement metrics.\\\\n\\\\n## Metrics\\\\n- Frequency: 208\\\\n- Severity: 7\\\\n- Severity reasoning: The severity score is set at 7 because the CTA element on the order fulfillment page is underperforming despite 208 unique sessions showing engagement. With a current average of 176.29 interactions and a target of 220.36, the design anomaly poses a significant risk to conversion rates, suggesting that misalignment in design or placement could lead to substantial performance losses.\\\\n- Confidence: 0.85\\\\n- Confidence reasoning: We assign a confidence score of 0.85 based on robust data derivations. The metrics \\\\u2013 current average CTA interactions of 176.29, a target of 220.36 after applying a 25% uplift, and a reach fraction of 0.3032 \\\\u2013 are directly computed from detailed SQL queries executed over complete weekly data. These traceable computations reinforce the reliability of this insight.\\\\n\", \"okr_name\": \"Enhance CTA Element Visibility on Heatmaps\", \"timestamp\": \"1739734352545\", \"suggestion_count\": 0}, {\"markdown\": \"# Insight Analysis\\\\n\\\\n## Data Statement\\\\nThe form fill conversion rate on the \\'Get Pricing\\' page is 4.5% compared to a higher rate of 7.0% on the \\'Contact Us\\' page. With a target uplift of 25%, the expected rate on \\'Get Pricing\\' is 5.625%, and the reach fraction is 40.0% of sessions. This underperformance indicates a clear opportunity to optimize the design and placement of the form button on the \\'Get Pricing\\' page.\\\\n\\\\n## Problem Statement\\\\nThe \\'Get Pricing\\' page shows a significantly lower conversion rate (simulated at 4.5%) compared to the \\'Contact Us\\' page (7.0%). Given a reach fraction of 40.0% (360 engaged sessions out of 900), the suboptimal conversion suggests that design or placement issues may be impacting user engagement and form fills.\\\\n\\\\n## Business Objective\\\\nIncrease on-site CTR and improve form fill conversion rates by optimizing the design and placement of key conversion elements.\\\\n\\\\n## Hypothesis\\\\nBy redesigning and repositioning the primary form button on the \\'Get Pricing\\' page, we expect to close the conversion gap between \\'Get Pricing\\' and \\'Contact Us\\', ultimately improving overall form fill conversions.\\\\n\\\\n## Metrics\\\\n- Frequency: 360\\\\n- Severity: 6\\\\n- Severity reasoning: A severity of 6 is justified by the significant shortfall in the conversion rate on the \\'Get Pricing\\' page compared to \\'Contact Us\\', combined with a substantial reach fraction indicating many users are affected.\\\\n- Confidence: 0.9\\\\n- Confidence reasoning: The metrics are derived from reproducible simulated values and a fixed calculation, providing a clear direction for improvement that is supported by the underlying data.\\\\n\", \"okr_name\": \"Form Fill and On-Site CTR Evaluation\", \"timestamp\": \"1739801544115\", \"suggestion_count\": 2}]\\nOnly choose 1 OKR to use as a base. Prioritize choosing an OKR where the insight count is low and has a greater impact on the business.\\nIMPORTANT: The task is not complete unless the Insight is explicitly stored by the insights_analyst agent.', 'stream_key': 'mugBgh8cEJ9tXiyAgZ1hm2fYRtaa1Rnw241h4BSO', 'options': {'type': 'insights'}, 'agent_instructions': {}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call.inputs['example']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import litellm\n",
    "from litellm.utils import trim_messages\n",
    "from litellm import completion\n",
    "import json\n",
    "# Flag to check if Vertex AI is initialized\n",
    "vertex_ai_initialized = False\n",
    "\n",
    "def get_api_key(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "    get_secret_value_response = client.get_secret_value(\n",
    "        SecretId=secret_name\n",
    "    )\n",
    "    return json.loads(get_secret_value_response[\"SecretString\"])\n",
    "\n",
    "def initialize_vertex_ai():\n",
    "    \"\"\"Initialize Vertex AI with service account credentials\"\"\"\n",
    "    global vertex_ai_initialized\n",
    "    if not vertex_ai_initialized:\n",
    "        AI_KEYS = get_api_key(\"AI_KEYS\")\n",
    "        litellm.api_key = AI_KEYS[\"LLM_API_KEY\"]\n",
    "        litellm.api_base = \"https://llms.sitewiz.ai\"\n",
    "        litellm.enable_json_schema_validation = True\n",
    "        \n",
    "        vertex_ai_initialized = True\n",
    "\n",
    "def run_completion_with_fallback(messages=None, prompt=None, models=[\"video\"], response_format=None, temperature=None):\n",
    "    \"\"\"\n",
    "    Run completion with fallback to evaluate.\n",
    "    \"\"\"\n",
    "    initialize_vertex_ai()\n",
    "\n",
    "    if messages is None:\n",
    "        if prompt is None:\n",
    "            raise ValueError(\"Either messages or prompt should be provided.\")\n",
    "        else:\n",
    "            messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    trimmed_messages = messages\n",
    "    try:\n",
    "        trimmed_messages = trim_messages(messages, model)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    for model in models:\n",
    "        try:\n",
    "            if response_format is None:\n",
    "                response = completion(model=\"litellm_proxy/\"+model, messages=trimmed_messages, temperature=temperature)\n",
    "                content = response.choices[0].message.content\n",
    "                return content\n",
    "            else:\n",
    "                response = completion(model=\"litellm_proxy/\"+model, messages=trimmed_messages, response_format=response_format, temperature=temperature)\n",
    "                content = json.loads(response.choices[0].message.content)  \n",
    "                if isinstance(response_format, BaseModel):\n",
    "                    response_format.model_validate(content)\n",
    "\n",
    "                return content\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to run completion with model {model}. Error: {str(e)}\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, this is a large codebase, so let's break down potential areas for improvement.  I'll focus on general good practices, maintainability, and potential performance bottlenecks.  I'll provide specific examples based on the provided files, but keep in mind this is a general overview, and more in-depth analysis would be required for targeted optimization.\n",
      "\n",
      "**1. General Code Structure & Design:**\n",
      "\n",
      "*   **Modularity and Abstraction:** The code is broken into many files, which is good. However, look for opportunities to further abstract common functionalities into reusable classes or functions.  For example, database interaction logic or the logic for calling LLMs could be consolidated.\n",
      "*   **Dependency Injection:** In many of the `create_*_agent` functions, there's a `get_llm_config` function passed as an argument. This is a good start, but consider using a dependency injection framework (even a simple one) to manage and provide these configurations more consistently and testably.  This will also help with configuration management across different environments.\n",
      "*   **Configuration Management:** Instead of hardcoding settings or relying solely on environment variables, implement a more robust configuration management system.  Consider using a library like `pydantic-settings` or `dynaconf` for easier handling of configuration files, environment variables, and secrets. This will ensure there are not key value pairs in the wrong place.\n",
      "\n",
      "**2. Error Handling & Logging:**\n",
      "\n",
      "*   **Consistent Error Handling:** The code has several `try...except` blocks. Standardize the error handling approach. Log exceptions with detailed information (tracebacks) using the `logging` module, and consider using custom exception classes for specific error scenarios.  Avoid generic `except Exception as e:` without at least logging the exception.\n",
      "*   **More Informative Logging:**  Add more logging statements to trace the execution flow, especially around key function calls, tool executions, and decision points.  Use different logging levels (DEBUG, INFO, WARNING, ERROR) appropriately.\n",
      "*   **Consider adding comments with clear explanation at every function**\n",
      "*   **Add type hints**\n",
      "\n",
      "**3. Database Interactions:**\n",
      "\n",
      "*   **Connection Pooling:**  The `get_db_connection` function seems to establish a new connection every time it's called. This is inefficient. Implement a connection pool (e.g., using `psycopg2.pool`) to reuse connections and reduce overhead.\n",
      "*   **SQL Injection Prevention:** Make absolutely sure that all SQL queries that are composed dynamically are properly parameterized to prevent SQL injection vulnerabilities.  The `run_sitewiz_query` function should *always* use parameterized queries when incorporating user-provided data.\n",
      "*   **Database Abstraction (ORM):** Consider using an ORM (like SQLAlchemy) for more complex database interactions. This can improve code readability, maintainability, and security.\n",
      "*   **Use of Connection:**  Ensure that the connections are properly closed. Even with connection pooling, the connections should be properly released back to the pool. Use context managers (`with conn:`) to automatically handle resource cleanup.\n",
      "\n",
      "**4. LLM Interactions:**\n",
      "\n",
      "*   **Prompt Engineering:**  Review the prompts used for the LLMs. Ensure they are clear, concise, and provide sufficient context for the LLMs to generate accurate and relevant responses. Experiment with different prompt formats and techniques.\n",
      "*   **Model Fallback Strategy:** The `run_completion_with_fallback` function provides a good fallback mechanism. Consider adding metrics and monitoring to track the frequency of fallbacks to different models. This can help you identify the most reliable models and optimize your costs.\n",
      "*   **Prompt Templating:**  Use template engines (like Jinja2) to manage complex prompts. This will improve readability and make it easier to modify prompts without directly changing the code.\n",
      "*    **Consider making prompts external from the file:**  This will increase the file's size and decrease readability\n",
      "\n",
      "**5. Asynchronous Programming:**\n",
      "\n",
      "*   **Aiohttp vs Requests:** The `make_requests` function uses `aiohttp` for asynchronous requests, which is good.  Ensure that you consistently use asynchronous libraries (like `asyncpg` for database interactions) throughout your code to avoid blocking the event loop.\n",
      "*   **Task Management:**  For complex asynchronous workflows, consider using a task queue (like Celery or Redis Queue) to manage and distribute tasks.\n",
      "\n",
      "**6. Code Style & Conventions:**\n",
      "\n",
      "*   **PEP 8 Compliance:**  Use a code formatter (like `black`) and a linter (like `flake8`) to enforce consistent code style and identify potential issues.\n",
      "*   **Type Hints:** Add type hints to all function signatures and variables. This will improve code readability, maintainability, and help catch type-related errors early on.\n",
      "\n",
      "**7. Tools:**\n",
      "\n",
      "*   **Caching:** Implement caching for frequently accessed data to reduce latency and improve performance. Libraries like `cachetools` or Redis can be used for caching.\n",
      "*   **Refactor large functions to smaller functions and test that these smaller functions actually work.**\n",
      "*   **Check the dependencies to see if there are unnecessary dependencies that can be removed to reduce the size and loading time.**\n",
      "\n",
      "**Specific Examples (Illustrative):**\n",
      "\n",
      "*   **`backend/agents/data_analyst_group/utils/functions.py`:**\n",
      "\n",
      "    ```python\n",
      "    def get_db_connection():\n",
      "        \"\"\"Get database connection with optimizations\"\"\"\n",
      "        secret = get_secret_fetch()\n",
      "        conn = psycopg2.connect(\n",
      "            dbname=secret['dbname'],\n",
      "            user=secret['username'],\n",
      "            password=secret['password'],\n",
      "            host=secret['host'],\n",
      "            port=secret['port'],\n",
      "            options=f'-c statement_timeout={QUERY_TIMEOUT}'\n",
      "        )\n",
      "        return conn\n",
      "    ```\n",
      "\n",
      "    **Improved:**\n",
      "\n",
      "    ```python\n",
      "    import psycopg2\n",
      "    from psycopg2 import pool\n",
      "\n",
      "    db_pool = None  # Initialize connection pool\n",
      "\n",
      "    def initialize_db_pool():\n",
      "        global db_pool\n",
      "        if db_pool is None:\n",
      "            secret = get_secret_fetch()\n",
      "            db_pool = pool.SimpleConnectionPool(\n",
      "                minconn=1,  # Adjust as needed\n",
      "                maxconn=10, # Adjust as needed\n",
      "                dbname=secret['dbname'],\n",
      "                user=secret['username'],\n",
      "                password=secret['password'],\n",
      "                host=secret['host'],\n",
      "                port=secret['port'],\n",
      "                options=f'-c statement_timeout={QUERY_TIMEOUT}'\n",
      "            )\n",
      "\n",
      "    def get_db_connection():\n",
      "        \"\"\"Get database connection from pool\"\"\"\n",
      "        if db_pool is None:\n",
      "            initialize_db_pool()\n",
      "        return db_pool.getconn()\n",
      "\n",
      "    def release_db_connection(conn):\n",
      "        if db_pool is not None:\n",
      "            db_pool.putconn(conn)\n",
      "\n",
      "    def execute_query(query: str, params: tuple = None): # Added params for security\n",
      "        \"\"\"Execute a query and return the results\"\"\"\n",
      "        conn = None\n",
      "        cursor = None\n",
      "        try:\n",
      "            conn = get_db_connection()\n",
      "            cursor = conn.cursor()\n",
      "            cursor.execute(query, params) # Use parameterized query\n",
      "            results = cursor.fetchall()\n",
      "            conn.commit()\n",
      "            return convert_decimal(results)\n",
      "        except Exception as e:\n",
      "            print(f\"Error executing query: {e}\")\n",
      "            if conn:\n",
      "                conn.rollback() # Rollback on error\n",
      "            raise e # Re-raise to be handled higher up\n",
      "\n",
      "        finally:\n",
      "            if cursor:\n",
      "                cursor.close()\n",
      "            if conn:\n",
      "                release_db_connection(conn)  # Return connection to pool\n",
      "    ```\n",
      "\n",
      "    Key changes:\n",
      "\n",
      "    *   Connection pooling to reuse connections.\n",
      "    *   Parameterized queries to prevent SQL injection (see `execute_query`).\n",
      "    *   Explicitly close cursor and return connection to the pool.\n",
      "\n",
      "*   **`backend/agents/data_analyst_group/prompts/suggestion_prompts.py`:** Store text in JSON or in the database instead of storing it in the code.\n",
      "\n",
      "**8. Security:**\n",
      "\n",
      "*   **Secrets Management:** Review how secrets (API keys, database credentials) are stored and accessed. Use a secrets management system (like AWS Secrets Manager, HashiCorp Vault, or similar) to store secrets securely and prevent them from being hardcoded in the code.\n",
      "*   **Input Validation:** Carefully validate all input data to prevent injection attacks (SQL injection, command injection, etc.). Use appropriate sanitization techniques.\n",
      "*   **Dependency Scanning:** Use tools like `snyk` or `whitesource` to scan your dependencies for known vulnerabilities.\n",
      "*   **Penetration Testing:** Perform penetration testing on your application to identify potential security flaws.\n",
      "\n",
      "By addressing these areas, you can significantly improve the quality, maintainability, performance, and security of your code. Remember to prioritize the areas that are most critical to your application's success and focus on making incremental improvements over time.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./extracted_code.txt', 'r', encoding='utf-8') as file:\n",
    "    code = file.read()\n",
    "\n",
    "prompt = f\"\"\"I have the following documents:\n",
    "\n",
    "Code:\n",
    "```\n",
    "{code}\n",
    "```\n",
    "\n",
    "\n",
    "How can the code be improved?\"\"\"\n",
    "\n",
    "\n",
    "output = run_completion_with_fallback(prompt=prompt)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sitewiz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
